{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vrtdr5UF_TyT",
        "JLaq0LFXBBI9",
        "vSc5RUhgBu_3",
        "aptZI3yhEOlW",
        "WvPQoLBzGvAS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lipchenko/lipchenko_HSE_student/blob/main/my_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1: выгрузка файлов"
      ],
      "metadata": {
        "id": "aa2G_JERA7yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Зайдите в репозиторий датасетов для обучения диалоговых систем\n",
        "2. Найдите все файлы с расширением *.txt (их всего 5 в репозитории)\n",
        "3. Выгрузите каждый файл с помощью утилиты `wget`\n",
        "- Для этого откройте датасет в браузере, например, https://github.com/Phylliida/Dialogue-Datasets/blob/master/TwitterLowerAsciiCorpus.txt\n",
        "- Затем найдите кнопку `raw`, которая откроет вам файл \"как есть\" (как в блокноте!)\n",
        "- Скопируйте ссылку на файл (она выглядит так: https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt)\n",
        "- Воспользуйтесь `wget`\n",
        "---\n",
        "Как использовать `wget`:\n",
        "---"
      ],
      "metadata": {
        "id": "vrtdr5UF_TyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swBssiVj90wr",
        "outputId": "6f4917f9-540c-41ca-8ab1-56e47478b92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 20:28:40--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "twitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-05 20:28:41 (4.73 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь:\n",
        "- ! указывает на то, что это консольная утилита, а не код на python\n",
        "- после wget идет полный адрес ссылки для скачивания файла\n",
        "- после параметра `-O` указываем название файла, под которым мы хотим скачать файл"
      ],
      "metadata": {
        "id": "kekDrEGyAXUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь: повторите процедуру для остальных файлов (всего должно быть 5 файлов)\n",
        "#Файл номер 1\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt\n",
        "\n",
        "#Файл номер 2\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt -O BNCCorpus.txt\n",
        "\n",
        "#Файл номер 3\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt -O twitter2.txt\n",
        "\n",
        "#Файл номер 4\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt -O BNCSplitWordsCorpus.txt\n",
        "\n",
        "#Файл номер 5\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt -O MovieCorpus.txt"
      ],
      "metadata": {
        "id": "1FAveoWrAWm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8ecece-8570-450f-f437-205e821ebca4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-05 20:28:43--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "twitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-05 20:28:43 (4.16 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n",
            "--2025-12-05 20:28:43--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19081694 (18M) [text/plain]\n",
            "Saving to: ‘BNCCorpus.txt’\n",
            "\n",
            "BNCCorpus.txt       100%[===================>]  18.20M  49.3MB/s    in 0.4s    \n",
            "\n",
            "2025-12-05 20:28:44 (49.3 MB/s) - ‘BNCCorpus.txt’ saved [19081694/19081694]\n",
            "\n",
            "--2025-12-05 20:28:44--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 612338 (598K) [text/plain]\n",
            "Saving to: ‘twitter2.txt’\n",
            "\n",
            "twitter2.txt        100%[===================>] 597.99K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-05 20:28:44 (4.19 MB/s) - ‘twitter2.txt’ saved [612338/612338]\n",
            "\n",
            "--2025-12-05 20:28:44--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173003 (18M) [text/plain]\n",
            "Saving to: ‘BNCSplitWordsCorpus.txt’\n",
            "\n",
            "BNCSplitWordsCorpus 100%[===================>]  18.28M  46.4MB/s    in 0.4s    \n",
            "\n",
            "2025-12-05 20:28:45 (46.4 MB/s) - ‘BNCSplitWordsCorpus.txt’ saved [19173003/19173003]\n",
            "\n",
            "--2025-12-05 20:28:45--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976724 (16M) [text/plain]\n",
            "Saving to: ‘MovieCorpus.txt’\n",
            "\n",
            "MovieCorpus.txt     100%[===================>]  16.19M  44.0MB/s    in 0.4s    \n",
            "\n",
            "2025-12-05 20:28:46 (44.0 MB/s) - ‘MovieCorpus.txt’ saved [16976724/16976724]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2: открываем файлы"
      ],
      "metadata": {
        "id": "JLaq0LFXBBI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изучите туториал по работе с файлами, который вы получили в чате. Каждый файл нужно теперь открыть, а его содержание - записать в переменную *любым удобным вам способом*\n",
        "\n",
        "Пример:"
      ],
      "metadata": {
        "id": "AjNtW5R1BI7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "_uJqiGUpBFEV",
        "outputId": "c6b44f2c-ffa7-401f-9404-6d94c0027b48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_data(filename):\n",
        "  with open(filename, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "\n",
        "  print(\"Файл успешно загружен!\")\n",
        "  print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "  dataset_content[:100]\n",
        "\n",
        "new_data('twitter.txt')\n",
        "new_data('BNCCorpus.txt')\n",
        "new_data('twitter2.txt')\n",
        "new_data('BNCSplitWordsCorpus.txt')\n",
        "new_data('MovieCorpus.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiUC6WM8G8ic",
        "outputId": "25b2b388-47e5-4910-b11b-ead798cc809b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n",
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n",
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n",
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n",
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3: первичный анализ"
      ],
      "metadata": {
        "id": "vSc5RUhgBu_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем статистику для каждого файла по образцу:"
      ],
      "metadata": {
        "id": "ui-vA_4wB76-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "def statistics(filename):\n",
        "  with open(filename, 'r', encoding='utf-8') as file:\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "    total_lines = 0         # общее количество строк\n",
        "    total_words = 0         # общее количество слов\n",
        "    total_chars = 0         # общее количество символов\n",
        "    non_empty_lines = 0\n",
        "    max_line_length = 0   # максимальная длина строки\n",
        "    min_line_length = None  # минимальная длина строки\n",
        "\n",
        "\n",
        "    for line in file:\n",
        "          total_lines += 1\n",
        "          for word in line.split(): #разделила на строки\n",
        "            total_words += len(word)\n",
        "            for char in word:\n",
        "              total_chars += len(line)\n",
        "          if len(line) > 0:\n",
        "            non_empty_lines += 1\n",
        "      # Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "          if len(line) > max_line_length:\n",
        "              max_line_length = len(line)\n",
        "          if min_line_length is None:        #\n",
        "              min_line_length = len(line)\n",
        "          elif len(line) < min_line_length:\n",
        "              min_line_length = len(line)\n",
        "#Не совсем понимаю, как релизовать подсчет максимальной длинны и минимальной при помощи счетчика.\n",
        "#Хотела сначала использовать максимальное большое значение для max length (2**32), и использовать простые операторы подсчета длины:\n",
        "#К примеру, min_line_length = min(len(line), min_line_length) или max(len(line)), но llm подсказала, что это решение неверное, так как считает длину некорректно.\n",
        "#Таким образом, решила использовать условные операторы.\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "    print(f\"Всего строк: {total_lines}\")\n",
        "    print(f\"Непустых строк: {non_empty_lines}\")\n",
        "    print(f\"Всего слов: {total_words}\")\n",
        "    print(f\"Всего символов: {total_chars}\")\n",
        "    print(f\"Макс. длина строки: {max_line_length}\")\n",
        "    print(f\"Мин. длина строки: {min_line_length}\")\n",
        "\n",
        "statistics('twitter.txt')\n",
        "statistics('BNCCorpus.txt')\n",
        "statistics('twitter2.txt')\n",
        "statistics('BNCSplitWordsCorpus.txt')\n",
        "statistics('MovieCorpus.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XliSd4K4Byym",
        "outputId": "c5770497-08ab-48a0-b503-06dafaa36bed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16556\n",
            "Непустых строк: 16556\n",
            "Всего слов: 472644\n",
            "Всего символов: 39159279\n",
            "Макс. длина строки: 147\n",
            "Мин. длина строки: 1\n",
            "Всего строк: 611014\n",
            "Непустых строк: 611014\n",
            "Всего слов: 15116234\n",
            "Всего символов: 1228166571\n",
            "Макс. длина строки: 2703\n",
            "Мин. длина строки: 1\n",
            "Всего строк: 16556\n",
            "Непустых строк: 16556\n",
            "Всего слов: 477493\n",
            "Всего символов: 39598387\n",
            "Макс. длина строки: 147\n",
            "Мин. длина строки: 1\n",
            "Всего строк: 611014\n",
            "Непустых строк: 611014\n",
            "Всего слов: 15116234\n",
            "Всего символов: 1240978873\n",
            "Макс. длина строки: 2774\n",
            "Мин. длина строки: 1\n",
            "Всего строк: 304713\n",
            "Непустых строк: 304713\n",
            "Всего слов: 13766158\n",
            "Всего символов: 1753699530\n",
            "Макс. длина строки: 3040\n",
            "Мин. длина строки: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4: чистка текста"
      ],
      "metadata": {
        "id": "aptZI3yhEOlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def cleaned_text(filename):\n",
        "  cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "  all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "  with open(filename, 'r', encoding='utf-8') as file:\n",
        "\n",
        "    for line in file:\n",
        "      cleaned_line = line.strip()\n",
        "      cleaned_line = re.sub(r'[^\\w\\s]', '', cleaned_line)\n",
        "      cleaned_line = re.sub(r'\\s+', ' ', cleaned_line)\n",
        "      cleaned_line = cleaned_line.lower()\n",
        "      cleaned_lines.append(cleaned_line)\n",
        "      for word in cleaned_line.split():\n",
        "        if len(word) >= 1:\n",
        "          all_cleaned_words.append(word)\n",
        "\n",
        "    # Ваш код здесь: реализуйте очистку с помощью цикла for и RegEx\n",
        "    # 1. Используйте strip для удаления лишних пробелов из строки\n",
        "    # 2. Очищаем строку: оставляем только буквы, цифры и пробелы\n",
        "    # 3. Убираем лишние пробелы\n",
        "    # 4. Приводим к нижнему регистру\n",
        "    # 5. Собираем все слова после очистки в единый список\n",
        "    #    - не фиксируем слова короче 1 символа\n",
        "\n",
        "    # Выводим результат для каждого текста по образцу\n",
        "    print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "    print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")\n",
        "    return all_cleaned_words\n",
        "\n",
        "all_cleaned_words1 = cleaned_text('twitter.txt')\n",
        "all_cleaned_words2 = cleaned_text('BNCCorpus.txt')\n",
        "all_cleaned_words3 = cleaned_text('twitter2.txt')\n",
        "all_cleaned_words4 = cleaned_text('BNCSplitWordsCorpus.txt')\n",
        "all_cleaned_words5 = cleaned_text('MovieCorpus.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDEshS1DMo4",
        "outputId": "ab617102-097f-41b5-c357-52dbf8e992e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: whats up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 112155\n",
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3719812\n",
            "Пример очищенной строки: whats up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 112172\n",
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 4049197\n",
            "Пример очищенной строки: colonel durnford william vereker i hear you ve been seeking officers...\n",
            "Всего очищенных слов: 3176515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 5: статистика"
      ],
      "metadata": {
        "id": "WvPQoLBzGvAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 1: получаем статистику распределений длин слов"
      ],
      "metadata": {
        "id": "Iirxb-yneJqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cleaned_data(filename, all_cleaned_words):\n",
        "    total_words = len(all_cleaned_words)\n",
        "    total_chars = 0\n",
        "    word_lengths = []\n",
        "\n",
        "    # Ваш код здесь: создайте список длин слов word_lengths\n",
        "    #                и посчитайте общее количество символов total_chars\n",
        "    # Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "    word_length_count = {}\n",
        "\n",
        "\n",
        "    for word in all_cleaned_words:\n",
        "      length = len(word)\n",
        "      word_lengths.append(length)\n",
        "      if length in word_length_count:\n",
        "        word_length_count[length] += 1\n",
        "      else:\n",
        "        word_length_count[length] = 1\n",
        "      total_chars += length\n",
        "\n",
        "    # Ожидаемый результат:\n",
        "    print(f\"Слов после очистки: {total_words}\")\n",
        "    print(f\"Символов после очистки: {total_chars}\")\n",
        "    print(\"Распределение длин слов:\")\n",
        "    for length in sorted(word_length_count.keys()):\n",
        "        print(f\"  {length} букв: {word_length_count[length]} слов\")\n",
        "\n",
        "cleaned_data('twitter.txt', all_cleaned_words1)\n",
        "cleaned_data('BNCCorpus.txt', all_cleaned_words2)\n",
        "cleaned_data('twitter2.txt', all_cleaned_words3)\n",
        "cleaned_data('BNCSplitWordsCorpus.txt', all_cleaned_words4)\n",
        "cleaned_data('MovieCorpus.txt', all_cleaned_words5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Z1tTq5DQFA",
        "outputId": "62b5fc3b-7488-460b-f944-0172b972a774"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 112155\n",
            "Символов после очистки: 451047\n",
            "Распределение длин слов:\n",
            "  1 букв: 7243 слов\n",
            "  2 букв: 19608 слов\n",
            "  3 букв: 24774 слов\n",
            "  4 букв: 25463 слов\n",
            "  5 букв: 13276 слов\n",
            "  6 букв: 7903 слов\n",
            "  7 букв: 6085 слов\n",
            "  8 букв: 3465 слов\n",
            "  9 букв: 2053 слов\n",
            "  10 букв: 1115 слов\n",
            "  11 букв: 541 слов\n",
            "  12 букв: 272 слов\n",
            "  13 букв: 146 слов\n",
            "  14 букв: 76 слов\n",
            "  15 букв: 44 слов\n",
            "  16 букв: 27 слов\n",
            "  17 букв: 17 слов\n",
            "  18 букв: 11 слов\n",
            "  19 букв: 11 слов\n",
            "  20 букв: 6 слов\n",
            "  21 букв: 2 слов\n",
            "  22 букв: 3 слов\n",
            "  23 букв: 1 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 3 слов\n",
            "  26 букв: 1 слов\n",
            "  27 букв: 2 слов\n",
            "  28 букв: 2 слов\n",
            "  33 букв: 1 слов\n",
            "  41 букв: 1 слов\n",
            "  51 букв: 1 слов\n",
            "  98 букв: 1 слов\n",
            "Слов после очистки: 3719812\n",
            "Символов после очистки: 14838140\n",
            "Распределение длин слов:\n",
            "  1 букв: 194977 слов\n",
            "  2 букв: 666389 слов\n",
            "  3 букв: 880968 слов\n",
            "  4 букв: 880766 слов\n",
            "  5 букв: 425302 слов\n",
            "  6 букв: 255069 слов\n",
            "  7 букв: 175610 слов\n",
            "  8 букв: 102856 слов\n",
            "  9 букв: 60865 слов\n",
            "  10 букв: 34706 слов\n",
            "  11 букв: 16675 слов\n",
            "  12 букв: 10611 слов\n",
            "  13 букв: 5627 слов\n",
            "  14 букв: 3330 слов\n",
            "  15 букв: 1970 слов\n",
            "  16 букв: 1292 слов\n",
            "  17 букв: 667 слов\n",
            "  18 букв: 559 слов\n",
            "  19 букв: 331 слов\n",
            "  20 букв: 262 слов\n",
            "  21 букв: 173 слов\n",
            "  22 букв: 162 слов\n",
            "  23 букв: 94 слов\n",
            "  24 букв: 98 слов\n",
            "  25 букв: 62 слов\n",
            "  26 букв: 45 слов\n",
            "  27 букв: 56 слов\n",
            "  28 букв: 32 слов\n",
            "  29 букв: 28 слов\n",
            "  30 букв: 31 слов\n",
            "  31 букв: 12 слов\n",
            "  32 букв: 34 слов\n",
            "  33 букв: 16 слов\n",
            "  34 букв: 14 слов\n",
            "  35 букв: 18 слов\n",
            "  36 букв: 17 слов\n",
            "  37 букв: 2 слов\n",
            "  38 букв: 3 слов\n",
            "  39 букв: 18 слов\n",
            "  40 букв: 3 слов\n",
            "  41 букв: 2 слов\n",
            "  42 букв: 6 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 3 слов\n",
            "  45 букв: 7 слов\n",
            "  47 букв: 4 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  53 букв: 1 слов\n",
            "  54 букв: 1 слов\n",
            "  56 букв: 2 слов\n",
            "  57 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 5 слов\n",
            "  60 букв: 7 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 4 слов\n",
            "  66 букв: 1 слов\n",
            "  87 букв: 1 слов\n",
            "  90 букв: 1 слов\n",
            "  104 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  112 букв: 1 слов\n",
            "  114 букв: 1 слов\n",
            "Слов после очистки: 112172\n",
            "Символов после очистки: 451142\n",
            "Распределение длин слов:\n",
            "  1 букв: 7250 слов\n",
            "  2 букв: 19607 слов\n",
            "  3 букв: 24775 слов\n",
            "  4 букв: 25464 слов\n",
            "  5 букв: 13273 слов\n",
            "  6 букв: 7902 слов\n",
            "  7 букв: 6089 слов\n",
            "  8 букв: 3472 слов\n",
            "  9 букв: 2054 слов\n",
            "  10 букв: 1116 слов\n",
            "  11 букв: 540 слов\n",
            "  12 букв: 273 слов\n",
            "  13 букв: 146 слов\n",
            "  14 букв: 76 слов\n",
            "  15 букв: 44 слов\n",
            "  16 букв: 27 слов\n",
            "  17 букв: 17 слов\n",
            "  18 букв: 11 слов\n",
            "  19 букв: 11 слов\n",
            "  20 букв: 6 слов\n",
            "  21 букв: 2 слов\n",
            "  22 букв: 3 слов\n",
            "  23 букв: 1 слов\n",
            "  24 букв: 1 слов\n",
            "  25 букв: 3 слов\n",
            "  26 букв: 1 слов\n",
            "  27 букв: 2 слов\n",
            "  28 букв: 2 слов\n",
            "  33 букв: 1 слов\n",
            "  41 букв: 1 слов\n",
            "  51 букв: 1 слов\n",
            "  98 букв: 1 слов\n",
            "Слов после очистки: 4049197\n",
            "Символов после очистки: 14838140\n",
            "Распределение длин слов:\n",
            "  1 букв: 294900 слов\n",
            "  2 букв: 792159 слов\n",
            "  3 букв: 989697 слов\n",
            "  4 букв: 983781 слов\n",
            "  5 букв: 445871 слов\n",
            "  6 букв: 243277 слов\n",
            "  7 букв: 151412 слов\n",
            "  8 букв: 75975 слов\n",
            "  9 букв: 42591 слов\n",
            "  10 букв: 18823 слов\n",
            "  11 букв: 5903 слов\n",
            "  12 букв: 3026 слов\n",
            "  13 букв: 1138 слов\n",
            "  14 букв: 282 слов\n",
            "  15 букв: 52 слов\n",
            "  16 букв: 19 слов\n",
            "  17 букв: 63 слов\n",
            "  18 букв: 22 слов\n",
            "  19 букв: 205 слов\n",
            "  24 букв: 1 слов\n",
            "Слов после очистки: 3176515\n",
            "Символов после очистки: 12689720\n",
            "Распределение длин слов:\n",
            "  1 букв: 174586 слов\n",
            "  2 букв: 548256 слов\n",
            "  3 букв: 733908 слов\n",
            "  4 букв: 746578 слов\n",
            "  5 букв: 389942 слов\n",
            "  6 букв: 222090 слов\n",
            "  7 букв: 160799 слов\n",
            "  8 букв: 88994 слов\n",
            "  9 букв: 54301 слов\n",
            "  10 букв: 30713 слов\n",
            "  11 букв: 13458 слов\n",
            "  12 букв: 6827 слов\n",
            "  13 букв: 3347 слов\n",
            "  14 букв: 1389 слов\n",
            "  15 букв: 612 слов\n",
            "  16 букв: 319 слов\n",
            "  17 букв: 134 слов\n",
            "  18 букв: 90 слов\n",
            "  19 букв: 44 слов\n",
            "  20 букв: 29 слов\n",
            "  21 букв: 23 слов\n",
            "  22 букв: 11 слов\n",
            "  23 букв: 16 слов\n",
            "  24 букв: 14 слов\n",
            "  25 букв: 10 слов\n",
            "  26 букв: 1 слов\n",
            "  27 букв: 7 слов\n",
            "  28 букв: 1 слов\n",
            "  29 букв: 4 слов\n",
            "  30 букв: 4 слов\n",
            "  33 букв: 2 слов\n",
            "  34 букв: 2 слов\n",
            "  35 букв: 3 слов\n",
            "  38 букв: 1 слов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часть 2: частотность слов"
      ],
      "metadata": {
        "id": "gFZj9nmSeSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def words_frequency(filename, all_cleaned_words):\n",
        "\n",
        "    word_frequency = {}\n",
        "    for word in all_cleaned_words:\n",
        "        if word in word_frequency:\n",
        "            word_frequency[word] += 1\n",
        "        else:\n",
        "            word_frequency[word] = 1\n",
        "\n",
        "\n",
        "    word_count_pairs = []\n",
        "    for word, count in word_frequency.items():\n",
        "        word_count_pairs.append((count, word))\n",
        "\n",
        "    word_count_pairs.sort(reverse=True)   #Использовала .sort, так как программа работала около 30 минут и недавала результат.\n",
        "\n",
        "    print(\"Топ-10 самых частых слов:\")\n",
        "    for i in range(min(10, len(word_count_pairs))):\n",
        "        count, word = word_count_pairs[i]\n",
        "        print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "    unique_words = set()\n",
        "    for word in all_cleaned_words:\n",
        "        unique_words.add(word)\n",
        "\n",
        "    print(f\"Всего уникальных слов: {len(unique_words)}\")\n",
        "\n",
        "\n",
        "words_frequency('twitter.txt', all_cleaned_words1)\n",
        "words_frequency('BNCCorpus.txt', all_cleaned_words2)\n",
        "words_frequency('twitter2.txt', all_cleaned_words3)\n",
        "words_frequency('BNCSplitWordsCorpus.txt', all_cleaned_words4)\n",
        "words_frequency('MovieCorpus.txt', all_cleaned_words5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12uZ3UlLDSJv",
        "outputId": "17e9f4a6-92c4-4d66-a252-89e1bec5cbcf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых частых слов:\n",
            "  1. 'i': 3970 раз\n",
            "  2. 'the': 2918 раз\n",
            "  3. 'to': 2578 раз\n",
            "  4. 'you': 2308 раз\n",
            "  5. 'a': 2054 раз\n",
            "  6. 'and': 1658 раз\n",
            "  7. 'it': 1472 раз\n",
            "  8. 'my': 1197 раз\n",
            "  9. 'in': 1169 раз\n",
            "  10. 'that': 1167 раз\n",
            "Всего уникальных слов: 11302\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'i': 109106 раз\n",
            "  2. 'the': 108702 раз\n",
            "  3. 'you': 102312 раз\n",
            "  4. 'and': 82190 раз\n",
            "  5. 'it': 79950 раз\n",
            "  6. 'a': 74095 раз\n",
            "  7. 'to': 71616 раз\n",
            "  8. 'that': 54294 раз\n",
            "  9. 'yeah': 43973 раз\n",
            "  10. 'of': 41437 раз\n",
            "Всего уникальных слов: 120083\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'i': 3970 раз\n",
            "  2. 'the': 2918 раз\n",
            "  3. 'to': 2578 раз\n",
            "  4. 'you': 2308 раз\n",
            "  5. 'a': 2054 раз\n",
            "  6. 'and': 1658 раз\n",
            "  7. 'it': 1472 раз\n",
            "  8. 'my': 1197 раз\n",
            "  9. 'in': 1169 раз\n",
            "  10. 'that': 1167 раз\n",
            "Всего уникальных слов: 11322\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'i': 137175 раз\n",
            "  2. 'you': 116813 раз\n",
            "  3. 'the': 115660 раз\n",
            "  4. 'it': 91854 раз\n",
            "  5. 'and': 90807 раз\n",
            "  6. 'a': 81653 раз\n",
            "  7. 'to': 74145 раз\n",
            "  8. 'that': 60496 раз\n",
            "  9. 'yeah': 56744 раз\n",
            "  10. 'in': 44184 раз\n",
            "Всего уникальных слов: 20816\n",
            "Топ-10 самых частых слов:\n",
            "  1. 'you': 127577 раз\n",
            "  2. 'i': 102190 раз\n",
            "  3. 'the': 98925 раз\n",
            "  4. 'to': 80532 раз\n",
            "  5. 'a': 70628 раз\n",
            "  6. 'it': 47016 раз\n",
            "  7. 'and': 45493 раз\n",
            "  8. 'of': 39289 раз\n",
            "  9. 'that': 35133 раз\n",
            "  10. 'in': 34030 раз\n",
            "Всего уникальных слов: 65664\n"
          ]
        }
      ]
    }
  ]
}